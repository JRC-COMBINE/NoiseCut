{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3fa9a0",
   "metadata": {},
   "source": [
    "<!-- Author: Moein E. Samadi <moein.samadi@rwth-aachen.de> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75115e",
   "metadata": {},
   "source": [
    "# Classification with reduced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eac59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "\n",
    "from noisecut.model.noisecut_model import NoiseCut\n",
    "from noisecut.tree_structured.data_manipulator import DataManipulator\n",
    "\n",
    "# File path initialization\n",
    "input_file_path = \"../data/\"  # Update this to your actual path\n",
    "# List of dataset names\n",
    "dataset_names = [\"12D_E1\", \"12D_E2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3933fd",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### NoiseCut implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2d661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a dictionary for storing the results\n",
    "results_NC = {}\n",
    "\n",
    "# Loop through each file\n",
    "i = 0  # loop counter\n",
    "st = time.time()  # start timer\n",
    "for dataset_name in dataset_names:\n",
    "    i += 1\n",
    "    file_path = os.path.join(input_file_path, dataset_name)\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(\n",
    "        file_path, delimiter=\"    \", header=None, skiprows=1, engine=\"python\"\n",
    "    )\n",
    "    # Split the data into X and Y\n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "\n",
    "    # Add noise in data labeling. Then, train and test set split.\n",
    "    Training_set_size = 30\n",
    "    Noise_intencity = 5\n",
    "    manipulator = DataManipulator()\n",
    "    x_noisy, y_noisy = manipulator.get_noisy_data(\n",
    "        X, Y, percentage_noise=Noise_intencity\n",
    "    )\n",
    "    x_train, y_train, x_test, y_test = manipulator.split_data(\n",
    "        x_noisy, y_noisy, percentage_training_data=Training_set_size\n",
    "    )\n",
    "\n",
    "    # Read the structure of the data\n",
    "    with open(file_path, newline=\"\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=\" \")\n",
    "        first_row = next(reader)  # Read the first row\n",
    "    # Convert the string values to integers and store in an array\n",
    "    data_structure = [int(value) for value in first_row if value.strip() != \"\"]\n",
    "\n",
    "    # Fitting the hybrid model\n",
    "    mdl = NoiseCut(\n",
    "        n_input_each_box=data_structure\n",
    "    )  # 'n_input_each_box' should fit to the generated data\n",
    "    mdl.fit(x_train, y_train)\n",
    "\n",
    "    # AUC-ROC\n",
    "    y_pred_proba = mdl.predict_probability_of_being_1(x_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test.astype(int), y_pred_proba)\n",
    "    print(\"AUC-ROC=\", metrics.auc(fpr, tpr))\n",
    "    print()\n",
    "\n",
    "    # Store the values in the dictionary\n",
    "    results_NC[f\"dataset_{i}\"] = {\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"thresholds\": thresholds,\n",
    "    }\n",
    "\n",
    "run_time = time.time() - st\n",
    "print(\"Runtime(seconds)=\", run_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0699b0b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### XGBoost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd53716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost parameter tuning function and the model\n",
    "#\n",
    "\n",
    "\n",
    "def set_best_params_xgb(x_train, y_train, x_test, y_test):\n",
    "    tuned_parameters = [\n",
    "        {\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"gamma\": [0, 0.2, 0.4],\n",
    "            \"max_depth\": [4, 5, 6],\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "            \"early_stopping_rounds\": [10, 20],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Tuning hyperparametrs for the classifilcation accuracy\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb.XGBClassifier(),\n",
    "        param_grid=tuned_parameters,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=0)\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test, y_test, best_param):\n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        learning_rate=best_param[\"learning_rate\"],\n",
    "        gamma=best_param[\"gamma\"],\n",
    "        max_depth=best_param[\"max_depth\"],\n",
    "        n_estimators=best_param[\"n_estimators\"],\n",
    "        subsample=best_param[\"subsample\"],\n",
    "        colsample_bytree=best_param[\"colsample_bytree\"],\n",
    "        early_stopping_rounds=best_param[\"early_stopping_rounds\"],\n",
    "    )\n",
    "    \n",
    "    # Fitting the model with early stopping after 10 rpochs to avoid\n",
    "    # overfitting\n",
    "    clf = clf.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=0)\n",
    "    # make predictions for test data\n",
    "\n",
    "    ### The predicted labels ###\n",
    "    return clf.predict_proba(x_test), clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary for storing the results\n",
    "results_XGB = {}\n",
    "\n",
    "# Loop through each file\n",
    "i = 0  # loop counter\n",
    "st = time.time()  # start timer\n",
    "for dataset_name in dataset_names:\n",
    "    i += 1\n",
    "    file_path = os.path.join(input_file_path, dataset_name)\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(\n",
    "        file_path, delimiter=\"    \", header=None, skiprows=1, engine=\"python\"\n",
    "    )\n",
    "    # Split the data into X and Y\n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "\n",
    "    # Add noise in data labeling. Then, train and test set split.\n",
    "    Training_set_size = 30\n",
    "    Noise_intencity = 5\n",
    "    manipulator = DataManipulator()\n",
    "    x_noisy, y_noisy = manipulator.get_noisy_data(\n",
    "        X, Y, percentage_noise=Noise_intencity\n",
    "    )\n",
    "    x_train, y_train, x_test, y_test = manipulator.split_data(\n",
    "        x_noisy, y_noisy, percentage_training_data=Training_set_size\n",
    "    )\n",
    "\n",
    "    # Parameter tuning\n",
    "    best_params_xgb = set_best_params_xgb(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    # Fitting the XGBoost model\n",
    "    y_pred_proba, y_pred = xgb_model(\n",
    "        x_train, y_train, x_test, y_test, best_params_xgb\n",
    "    )\n",
    "\n",
    "    # AUC-ROC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba[::, 1])\n",
    "    print(\"AUC-ROC=\", metrics.auc(fpr, tpr))\n",
    "    print()\n",
    "\n",
    "    # Store the values in the dictionary\n",
    "    results_XGB[f\"dataset_{i}\"] = {\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"thresholds\": thresholds,\n",
    "    }\n",
    "\n",
    "run_time = time.time() - st\n",
    "print(\"Runtime(seconds)=\", run_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0e076",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87bba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.set_facecolor(\n",
    "    (0.95, 0.95, 0.95)\n",
    ")  # Adjust RGB values for a lighter gray color\n",
    "ax.title.set_fontsize(16)\n",
    "ax.xaxis.label.set_fontsize(14)\n",
    "ax.yaxis.label.set_fontsize(14)\n",
    "\n",
    "# Plot ROC curves\n",
    "ax.plot(\n",
    "    results_XGB[f\"dataset_{1}\"][\"fpr\"],\n",
    "    results_XGB[f\"dataset_{1}\"][\"tpr\"],\n",
    "    \"-\",\n",
    "    color=\"royalblue\",\n",
    "    label=\"XGBoost - Dataset-1 (AUC = {:.2f})\".format(\n",
    "        metrics.auc(\n",
    "            results_XGB[f\"dataset_{1}\"][\"fpr\"],\n",
    "            results_XGB[f\"dataset_{1}\"][\"tpr\"],\n",
    "        )\n",
    "    ),\n",
    "    linewidth=2.5,\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    results_NC[f\"dataset_{1}\"][\"fpr\"],\n",
    "    results_NC[f\"dataset_{1}\"][\"tpr\"],\n",
    "    \"--\",\n",
    "    color=\"royalblue\",\n",
    "    label=\"NoiseCut - Dataset-1 (AUC = {:.2f})\".format(\n",
    "        metrics.auc(\n",
    "            results_NC[f\"dataset_{1}\"][\"fpr\"],\n",
    "            results_NC[f\"dataset_{1}\"][\"tpr\"],\n",
    "        )\n",
    "    ),\n",
    "    linewidth=2.5,\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    results_XGB[f\"dataset_{2}\"][\"fpr\"],\n",
    "    results_XGB[f\"dataset_{2}\"][\"tpr\"],\n",
    "    \"-\",\n",
    "    color=\"peru\",\n",
    "    label=\"XGBoost - Dataset-2 (AUC = {:.2f})\".format(\n",
    "        metrics.auc(\n",
    "            results_XGB[f\"dataset_{2}\"][\"fpr\"],\n",
    "            results_XGB[f\"dataset_{2}\"][\"tpr\"],\n",
    "        )\n",
    "    ),\n",
    "    linewidth=2.5,\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    results_NC[f\"dataset_{2}\"][\"fpr\"],\n",
    "    results_NC[f\"dataset_{2}\"][\"tpr\"],\n",
    "    \"--\",\n",
    "    color=\"peru\",\n",
    "    label=\"NoiseCut - Dataset-2 (AUC = {:.2f})\".format(\n",
    "        metrics.auc(\n",
    "            results_NC[f\"dataset_{2}\"][\"fpr\"],\n",
    "            results_NC[f\"dataset_{2}\"][\"tpr\"],\n",
    "        )\n",
    "    ),\n",
    "    linewidth=2.5,\n",
    ")\n",
    "\n",
    "# Set title, labels, and legend\n",
    "ax.set_title(\"ROC Curves for classification with reduced training data\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(\"./multiple_roc_curve.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
